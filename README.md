

## SEMANTIC_VISUAL_SUPPORTED_Odemetry
implementation of VO using semantic feature extraction \(SFE\) of observations \(ROI\) for depth graph registration 
and precise relocalization solutions.

The solution compromises tracking state machine using sparse keypoints and semantic detections both for localization
and sparse mapping. Contrast to merely using keppoints in sparse SLAM, semnatic detection and matching of objects,
will greatly boost matching performance and gives more accurate sparse mapping.

Hence we extend the concept of lanmarks and data structures of covisibility graph, which leads to recalling keypoints through
ROI instead of using precomputed Bag of Words method. 

One of the application of such semantic slam is relocalization method. I implemented a full functional Relocalization based on
Bipartite landmarks matching for initial alignment and ICP algorithm to compute transform of a robot.

## Installation

### Dependencies

The most of libraries dependencies could be installed automatically by provided scripts in "$ROOT/scripts". But there are still some third party packages
needed be installed from source manually. Instructions or automation scripts provided. Third parties projects built from source will be distributed into "${ROOT}/vendors/${REPO}/". For example, we build 
tensorflow inside "${ROOT}/vendors/github.com/tensorflow_cc/tensorflow_cc/tensorflow".

### Env

The default system is built upon `Ubuntu 18.04` but other verions are also possible sopported. The hardware includes a physical GeForce RTX GPU (compute ability 7.5). According the
NV website and our tests, `cuda 10.1`, `cudnn` 7.6.5

### Step1: Build general dependencies of the project 

> bash scripts/install.sh

### Step2: Install anaconda conda and create virtual environments with python3.6 by conda

This will install c++ development libraries together with ros packages.

### Step3: Install python dependencies

This step will creates environment to run python codes inside projects, which `including all in one` Semantic Visual Supported Odemetry \(SVOSO\) tracker
in "${ROOT}/notebooks/svso_tracker.ipynb" and packages in "${ROOT}/python"

> bash scripts/init_python.sh

### Step4: Build Opencv4 libraries and python bindings

> bash scripts/thirdparty/linux/deb/apt/

This will automatically install build essentials, cmake with ssl support and opencv4 with python bindings to the current active python binary.

### Step5: C++ specific devleopment libraries

We moved our major backend into c++ version to make full use of concurrency and parallel computing abilities. The backend include a tracker to
estimate camera poses and extract landmarks registration,  key frame selection and keypoints depth triangluation procedures, local mapping with ROI and finally 
a relocalization algorithm based landmarks matching procedures.

##### Step 5-1: Install Protobuf

protobuf will be used by the cmake based project to build transportation layer of structurese a slam program and help in
 generating codes in c++ side. `Frame`, `Point3D`, `Pixel2D`, `RuntimeBlock` and etc. will be automatically generated by the programe.

> bash scripts/install_protoc.sh


##### Step 5-2: Install ceres, g2o and pangolin used for local mapping optimization

First fetch third parties project sources specified in ".gitmodules". You might encounter "git clone" problems using `git submodure init` command
. If that happens, download latest released sources `*.tar.gz` in whatever method that you feel good and extract the vendors location.

Then simple run

> bash scripts/build_ceres.sh
> bash scripts/build_g2o.sh
> bash scripts/build_pangolin.sh

Ceres relies on Eigen-3.3.3 where tensorflow 2.2.0-rc we are going to build uses patched eigen 3.3.9 mainted by
bazel system. To avoid conflicts I modified our `cmake/Modules/FindEigen3.cmake` to a version of bazel installed recorded in
`tensorflow/workspace.bzl` you can also find the library in `~/.cache/bazel/_bazel_${USER}/external/${HASH_CODE}/eigen_archive` [3]

##### Step 5-3: Build tensorflow c++ runtime from source code

Tensorflow is extremely large. First you need to build bazel then build shared library so that you can use in our cmake project.
Building Tensorfow with Bazel might takes at least 45 minutes \(tensorflow build time\) and up to 3 ~ 4 hours (bazel fetches dependencies).
The process is dependant on your network status.

> bash scipts/build_tensorflow.sh

If script does not work \(due to your network proxy, git ssh configuration, git cache setting and many other reasons\). Here are the procedures to do:

1) go to [tensorflow_cmake](https://github.com/cjweeks/tensorflow-cmake/blob/master/README.md) and follow the instructions. Note

Since bazel consumes a large portion of memories \[1\]\[2\] which could break your building process, replace bazel build command with the following one:

> sudo bazel build --jobs=8 --config=monolithic tensorflow:libtensorflow_all.so

## Build

Run

> mkdir -p build && cd build && cmake .. && make -j8

or using building script "${ROOT}/scripts/build.sh" where we provide flags control. The c++ implementation is automatically generated. other language protobuf implementation is generated by 

> bash scripts/gen_proto --lang=python

## References
```text
[1] github.com/tensorflow/tensorflow/issues/38183
[2] github.com/FloopCZ/tensorflow_cc/issues/213
[3] https://github.com/tensorflow/tensorflow/issues/38237
```
